{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Model",
      "provenance": [],
      "collapsed_sections": [
        "fLBLMkHiRSxg",
        "SnUnbyKzRX9y",
        "OiE6lvcDsRvA",
        "sfoCAmAHvGxt",
        "yfx_UwyavNGY",
        "iBReFVpivbX3",
        "ynDX5rvOvh97",
        "ZzKV5X6hvpvG"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vence-andersen/M5-Forecasting-Accuracy/blob/main/Ensemble_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnUnbyKzRX9y"
      },
      "source": [
        "# **Importing modules required and reading the pickle file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtCpiRRS1PmZ"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.metrics import mean_squared_log_error\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "from sklearn.metrics import make_scorer\r\n",
        "from sklearn.linear_model import ElasticNet\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from catboost import CatBoostRegressor\r\n",
        "from lightgbm import LGBMRegressor\r\n",
        "import pickle\r\n",
        "import dill\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from sklearn.metrics import mean_squared_error as mse\r\n",
        "from typing import Union\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpvSc4NYr2-I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyIkHAgx1PUb",
        "outputId": "f6d496e1-6005-40f0-d044-6f4991da04c5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "3gPRfcKX1RI_",
        "outputId": "2e0e2333-70d6-41b6-e83a-0ca1591fbc44"
      },
      "source": [
        "data = pd.read_pickle('/content/drive/MyDrive/new.pkl')\r\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>day</th>\n",
              "      <th>demand</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>lag_28</th>\n",
              "      <th>lag_30</th>\n",
              "      <th>lag_35</th>\n",
              "      <th>lag_42</th>\n",
              "      <th>lag_49</th>\n",
              "      <th>lag_56</th>\n",
              "      <th>lag_63</th>\n",
              "      <th>lag_70</th>\n",
              "      <th>rolling_median_5</th>\n",
              "      <th>rolling_median_7</th>\n",
              "      <th>rolling_median_28</th>\n",
              "      <th>rolling_median_56</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30490000</th>\n",
              "      <td>14370</td>\n",
              "      <td>1437</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1001</td>\n",
              "      <td>2</td>\n",
              "      <td>11339</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>2013</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.257812</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30490001</th>\n",
              "      <td>14380</td>\n",
              "      <td>1438</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1001</td>\n",
              "      <td>0</td>\n",
              "      <td>11339</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>2013</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  item_id  ...  rolling_median_28  rolling_median_56\n",
              "30490000  14370     1437  ...                0.0                0.0\n",
              "30490001  14380     1438  ...                0.0                0.0\n",
              "\n",
              "[2 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiE6lvcDsRvA"
      },
      "source": [
        "# **Train, Test Splits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS8IdEl2GJR",
        "outputId": "cb86ff11-d2f6-4959-c9c8-4eb4e2ead02a"
      },
      "source": [
        "# Now we are splitting our data into, Train, Test, Cross Validate.\r\n",
        "# Being a time series model, we are splitting the data based on time.\r\n",
        "\r\n",
        "# Records till day 1914 will be used for training the model.\r\n",
        "X_train = data[data['day']<1800]\r\n",
        "\r\n",
        "# Records after day 1942 will used for final test\r\n",
        "X_test = data[(data['day']>=1800)]\r\n",
        "\r\n",
        "y_train = X_train['demand']\r\n",
        "y_test = X_test['demand']\r\n",
        "\r\n",
        "# We are drpping the features which are not required.\r\n",
        "X_train.drop(['demand'],axis = 1,inplace = True)\r\n",
        "X_test.drop(['demand'],axis = 1,inplace = True)\r\n",
        "\r\n",
        "print(X_train.shape,y_train.shape)\r\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24361510, 27) (24361510,)\n",
            "(5183300, 27) (5183300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnZd-FkH24jr"
      },
      "source": [
        "# We are then splitting the train data 50-50 as D1 and D2\r\n",
        "X_train_D1 = X_train[X_train['day']<=1400]\r\n",
        "X_train_D2 = X_train[X_train['day']>1400]\r\n",
        "\r\n",
        "y_train_D1 = y_train[y_train.index <= X_train_D1.index[-1]].reset_index(drop=True)\r\n",
        "y_train_D2 = y_train[y_train.index > X_train_D1.index[-1]].reset_index(drop=True)\r\n",
        "\r\n",
        "X_train_D1.reset_index(drop=True, inplace=True)\r\n",
        "X_train_D2.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI_sa-485my-"
      },
      "source": [
        "def sampler(max_val):\r\n",
        "    \"\"\"This function is used to create a sample dataset\"\"\"\r\n",
        "\r\n",
        "    # siz variable defines that we are picking 70 percent of data with replacement\r\n",
        "    siz = np.int(max_val * 0.70)\r\n",
        "    return np.round(np.random.uniform(0,max_val-1, size=siz)).astype(int).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GccK0Uf8c7Y"
      },
      "source": [
        "# We are creating a sample dataset from X_train_D1 with 70 percent of data with replacement\r\n",
        "k1_train = X_train_D1.iloc[sampler(X_train_D1.shape[0])].sort_index()\r\n",
        "k1_test = y_train_D1[k1_train.index.tolist()]\r\n",
        "\r\n",
        "k2_train = X_train_D1.iloc[sampler(X_train_D1.shape[0])].sort_index()\r\n",
        "k2_test = y_train_D1[k2_train.index.tolist()]\r\n",
        "\r\n",
        "k3_train = X_train_D1.iloc[sampler(X_train_D1.shape[0])].sort_index()\r\n",
        "k3_test = y_train_D1[k3_train.index.tolist()]\r\n",
        "\r\n",
        "k4_train = X_train_D1.iloc[sampler(X_train_D1.shape[0])].sort_index()\r\n",
        "k4_test = y_train_D1[k4_train.index.tolist()]\r\n",
        "\r\n",
        "k5_train = X_train_D1.iloc[sampler(X_train_D1.shape[0])].sort_index()\r\n",
        "k5_test = y_train_D1[k5_train.index.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfoCAmAHvGxt"
      },
      "source": [
        "# **Base Model_1 LassoRegression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTK14GcVGgl_",
        "outputId": "70d24df7-4d95-4c77-f8da-286c713a232a"
      },
      "source": [
        "params = {'alpha' : [0.001,0.01,0.1,1,10,0.05,0.5]}\r\n",
        "\r\n",
        "lasso = Lasso()\r\n",
        "clf = GridSearchCV(estimator=lasso, param_grid=params,scoring='neg_mean_squared_error', cv=3,n_jobs=-1, return_train_score=True, verbose=2)\r\n",
        "clf.fit(k1_train, k1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  6.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=1000, normalize=False, positive=False,\n",
              "                             precompute=False, random_state=None,\n",
              "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 0.05, 0.5]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_squared_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "a6Ecf3qkgOY5",
        "outputId": "19af885f-302e-420a-8ff2-0dc55bb39d77"
      },
      "source": [
        "pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>235.910277</td>\n",
              "      <td>115.114222</td>\n",
              "      <td>0.449364</td>\n",
              "      <td>0.110772</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{'alpha': 0.001}</td>\n",
              "      <td>-9.300288</td>\n",
              "      <td>-6.728264</td>\n",
              "      <td>-5.593564</td>\n",
              "      <td>-7.207372</td>\n",
              "      <td>1.550722</td>\n",
              "      <td>6</td>\n",
              "      <td>-6.091510</td>\n",
              "      <td>-6.731293</td>\n",
              "      <td>-7.282431</td>\n",
              "      <td>-6.701745</td>\n",
              "      <td>0.486640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45.621883</td>\n",
              "      <td>12.618110</td>\n",
              "      <td>0.525556</td>\n",
              "      <td>0.009781</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'alpha': 0.01}</td>\n",
              "      <td>-8.061216</td>\n",
              "      <td>-6.731735</td>\n",
              "      <td>-5.593185</td>\n",
              "      <td>-6.795379</td>\n",
              "      <td>1.008574</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.093672</td>\n",
              "      <td>-6.732590</td>\n",
              "      <td>-7.284107</td>\n",
              "      <td>-6.703456</td>\n",
              "      <td>0.486429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.853307</td>\n",
              "      <td>6.788747</td>\n",
              "      <td>0.524748</td>\n",
              "      <td>0.007994</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'alpha': 0.1}</td>\n",
              "      <td>-8.042578</td>\n",
              "      <td>-6.746187</td>\n",
              "      <td>-5.606258</td>\n",
              "      <td>-6.798341</td>\n",
              "      <td>0.995307</td>\n",
              "      <td>3</td>\n",
              "      <td>-6.098085</td>\n",
              "      <td>-6.738449</td>\n",
              "      <td>-7.290629</td>\n",
              "      <td>-6.709054</td>\n",
              "      <td>0.487297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.539312</td>\n",
              "      <td>0.779091</td>\n",
              "      <td>0.469219</td>\n",
              "      <td>0.054044</td>\n",
              "      <td>1</td>\n",
              "      <td>{'alpha': 1}</td>\n",
              "      <td>-7.892976</td>\n",
              "      <td>-6.954936</td>\n",
              "      <td>-5.777192</td>\n",
              "      <td>-6.875035</td>\n",
              "      <td>0.865611</td>\n",
              "      <td>5</td>\n",
              "      <td>-6.199850</td>\n",
              "      <td>-6.832927</td>\n",
              "      <td>-7.392355</td>\n",
              "      <td>-6.808377</td>\n",
              "      <td>0.487148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.073261</td>\n",
              "      <td>0.033020</td>\n",
              "      <td>0.513901</td>\n",
              "      <td>0.006904</td>\n",
              "      <td>10</td>\n",
              "      <td>{'alpha': 10}</td>\n",
              "      <td>-14.649081</td>\n",
              "      <td>-14.232338</td>\n",
              "      <td>-13.567071</td>\n",
              "      <td>-14.149497</td>\n",
              "      <td>0.445596</td>\n",
              "      <td>7</td>\n",
              "      <td>-13.898914</td>\n",
              "      <td>-14.107087</td>\n",
              "      <td>-14.439518</td>\n",
              "      <td>-14.148506</td>\n",
              "      <td>0.222636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28.724928</td>\n",
              "      <td>9.965209</td>\n",
              "      <td>0.517216</td>\n",
              "      <td>0.003129</td>\n",
              "      <td>0.05</td>\n",
              "      <td>{'alpha': 0.05}</td>\n",
              "      <td>-8.054846</td>\n",
              "      <td>-6.738380</td>\n",
              "      <td>-5.600919</td>\n",
              "      <td>-6.798048</td>\n",
              "      <td>1.002700</td>\n",
              "      <td>2</td>\n",
              "      <td>-6.096868</td>\n",
              "      <td>-6.735576</td>\n",
              "      <td>-7.289137</td>\n",
              "      <td>-6.707194</td>\n",
              "      <td>0.487155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17.718964</td>\n",
              "      <td>4.316160</td>\n",
              "      <td>0.384079</td>\n",
              "      <td>0.080141</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'alpha': 0.5}</td>\n",
              "      <td>-7.953620</td>\n",
              "      <td>-6.826102</td>\n",
              "      <td>-5.665469</td>\n",
              "      <td>-6.815064</td>\n",
              "      <td>0.934167</td>\n",
              "      <td>4</td>\n",
              "      <td>-6.123702</td>\n",
              "      <td>-6.764859</td>\n",
              "      <td>-7.319644</td>\n",
              "      <td>-6.736068</td>\n",
              "      <td>0.488666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "0     235.910277    115.114222  ...         -6.701745         0.486640\n",
              "1      45.621883     12.618110  ...         -6.703456         0.486429\n",
              "2      23.853307      6.788747  ...         -6.709054         0.487297\n",
              "3      17.539312      0.779091  ...         -6.808377         0.487148\n",
              "4       5.073261      0.033020  ...        -14.148506         0.222636\n",
              "5      28.724928      9.965209  ...         -6.707194         0.487155\n",
              "6      17.718964      4.316160  ...         -6.736068         0.488666\n",
              "\n",
              "[7 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpoiO0BNkZr8",
        "outputId": "ab0524dd-4b49-40de-ae31-9f0bcedfdfd5"
      },
      "source": [
        "# We are here picking the worst performing model as our final meta_model will be a boosting type\r\n",
        "model_1 = Lasso(alpha=10)\r\n",
        "model_1.fit(k1_train, k1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=10, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False,\n",
              "      positive=False, precompute=False, random_state=None, selection='cyclic',\n",
              "      tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiQg4VEl_pd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPZIupuHmlgi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfx_UwyavNGY"
      },
      "source": [
        "# **Base Model_2 ElasticNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZWWF3l4ml6P",
        "outputId": "067834f0-2f5f-4d6c-8754-dc7b1d659168"
      },
      "source": [
        "params = {'alpha' : [0.001,0.01,0.1,1,10,0.05,0.5],\r\n",
        "          'l1_ratio' : [0.01,0.1,1]}\r\n",
        "\r\n",
        "elastic_net = ElasticNet(max_iter=250)\r\n",
        "clf = GridSearchCV(estimator=elastic_net, param_grid=params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, return_train_score=True)\r\n",
        "clf.fit(k2_train, k2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                                  l1_ratio=0.5, max_iter=250, normalize=False,\n",
              "                                  positive=False, precompute=False,\n",
              "                                  random_state=None, selection='cyclic',\n",
              "                                  tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'alpha': [0.001, 0.01, 0.1, 1, 10, 0.05, 0.5],\n",
              "                         'l1_ratio': [0.01, 0.1, 1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "MEVYlKvBml6S",
        "outputId": "21ea907a-31c0-494d-c9c4-22ef86b5fd64"
      },
      "source": [
        "pd.DataFrame(clf.cv_results_)[['param_alpha','param_l1_ratio','mean_test_score','std_test_score','mean_train_score','std_train_score']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>param_l1_ratio</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-7.008939</td>\n",
              "      <td>1.134876</td>\n",
              "      <td>-6.759825</td>\n",
              "      <td>0.445865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-7.005909</td>\n",
              "      <td>1.130846</td>\n",
              "      <td>-6.759842</td>\n",
              "      <td>0.445875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.970998</td>\n",
              "      <td>1.084996</td>\n",
              "      <td>-6.759922</td>\n",
              "      <td>0.445868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.984481</td>\n",
              "      <td>1.102746</td>\n",
              "      <td>-6.759879</td>\n",
              "      <td>0.445881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-6.956313</td>\n",
              "      <td>1.065944</td>\n",
              "      <td>-6.759961</td>\n",
              "      <td>0.445856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.846965</td>\n",
              "      <td>0.923624</td>\n",
              "      <td>-6.761565</td>\n",
              "      <td>0.445658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.891132</td>\n",
              "      <td>0.981579</td>\n",
              "      <td>-6.760438</td>\n",
              "      <td>0.445884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-6.846741</td>\n",
              "      <td>0.922911</td>\n",
              "      <td>-6.762024</td>\n",
              "      <td>0.445838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.849989</td>\n",
              "      <td>0.911426</td>\n",
              "      <td>-6.766891</td>\n",
              "      <td>0.446364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.847806</td>\n",
              "      <td>0.915853</td>\n",
              "      <td>-6.765857</td>\n",
              "      <td>0.446318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-6.849806</td>\n",
              "      <td>0.902225</td>\n",
              "      <td>-6.770848</td>\n",
              "      <td>0.446540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.927928</td>\n",
              "      <td>0.794401</td>\n",
              "      <td>-6.866240</td>\n",
              "      <td>0.445827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.950245</td>\n",
              "      <td>0.803917</td>\n",
              "      <td>-6.897457</td>\n",
              "      <td>0.445746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-7.139641</td>\n",
              "      <td>0.721879</td>\n",
              "      <td>-7.099201</td>\n",
              "      <td>0.440689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>-14.261981</td>\n",
              "      <td>0.461892</td>\n",
              "      <td>-14.261053</td>\n",
              "      <td>0.230800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.921386</td>\n",
              "      <td>1.020695</td>\n",
              "      <td>-6.760117</td>\n",
              "      <td>0.445865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-6.867403</td>\n",
              "      <td>0.950739</td>\n",
              "      <td>-6.760775</td>\n",
              "      <td>0.445790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.849541</td>\n",
              "      <td>0.918229</td>\n",
              "      <td>-6.765057</td>\n",
              "      <td>0.446237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-6.853537</td>\n",
              "      <td>0.929686</td>\n",
              "      <td>-6.762804</td>\n",
              "      <td>0.446097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-6.848433</td>\n",
              "      <td>0.913771</td>\n",
              "      <td>-6.766142</td>\n",
              "      <td>0.446294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.866858</td>\n",
              "      <td>0.855795</td>\n",
              "      <td>-6.793586</td>\n",
              "      <td>0.447572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_alpha param_l1_ratio  ...  mean_train_score  std_train_score\n",
              "0        0.001           0.01  ...         -6.759825         0.445865\n",
              "1        0.001            0.1  ...         -6.759842         0.445875\n",
              "2        0.001              1  ...         -6.759922         0.445868\n",
              "3         0.01           0.01  ...         -6.759879         0.445881\n",
              "4         0.01            0.1  ...         -6.759961         0.445856\n",
              "5         0.01              1  ...         -6.761565         0.445658\n",
              "6          0.1           0.01  ...         -6.760438         0.445884\n",
              "7          0.1            0.1  ...         -6.762024         0.445838\n",
              "8          0.1              1  ...         -6.766891         0.446364\n",
              "9            1           0.01  ...         -6.765857         0.446318\n",
              "10           1            0.1  ...         -6.770848         0.446540\n",
              "11           1              1  ...         -6.866240         0.445827\n",
              "12          10           0.01  ...         -6.897457         0.445746\n",
              "13          10            0.1  ...         -7.099201         0.440689\n",
              "14          10              1  ...        -14.261053         0.230800\n",
              "15        0.05           0.01  ...         -6.760117         0.445865\n",
              "16        0.05            0.1  ...         -6.760775         0.445790\n",
              "17        0.05              1  ...         -6.765057         0.446237\n",
              "18         0.5           0.01  ...         -6.762804         0.446097\n",
              "19         0.5            0.1  ...         -6.766142         0.446294\n",
              "20         0.5              1  ...         -6.793586         0.447572\n",
              "\n",
              "[21 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTbvOVCKml6V",
        "outputId": "2ce731c7-c79b-43aa-81ae-bc8e75346674"
      },
      "source": [
        "model_2 = ElasticNet(alpha=10,l1_ratio=1,max_iter=250)\r\n",
        "model_2.fit(k2_train, k2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=10, copy_X=True, fit_intercept=True, l1_ratio=1, max_iter=250,\n",
              "           normalize=False, positive=False, precompute=False, random_state=None,\n",
              "           selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WLYjnWbmlYQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMiYlP2zrAO5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBReFVpivbX3"
      },
      "source": [
        "# **Base Model_3 LinearRegression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPCPBfrQrCjm",
        "outputId": "2753426a-80c7-4482-c57d-11cd78589452"
      },
      "source": [
        "model_3 = LinearRegression(n_jobs=-1)\r\n",
        "model_3.fit(k3_train, k3_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "engK0Ozxrn4m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba0MreC_r5nm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynDX5rvOvh97"
      },
      "source": [
        "# **Base Model_4 CatBoostRegressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDucHAcer9H5"
      },
      "source": [
        "a = pd.DataFrame()\r\n",
        "for i in range(7):    \r\n",
        "    params = {'learning_rate' : np.round(np.random.rand(1)/10,3).tolist(),\r\n",
        "            'min_data_in_leaf' : np.random.randint(30,113, size=1).tolist()}\r\n",
        "\r\n",
        "    cat_boost = CatBoostRegressor(logging_level=\"Silent\", iterations=130)\r\n",
        "    clf = GridSearchCV(estimator=cat_boost, param_grid=params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, return_train_score=True)\r\n",
        "    clf.fit(k4_train, k4_test)\r\n",
        "    b = pd.DataFrame(clf.cv_results_)\r\n",
        "    a = pd.concat([a,b])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "HZuq9Y8V26ag",
        "outputId": "3a3e82e1-4407-46a9-faee-6d6597f33122"
      },
      "source": [
        "a['diff'] = a['mean_test_score'] - a['mean_train_score']\r\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_min_data_in_leaf</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>204.562277</td>\n",
              "      <td>4.050206</td>\n",
              "      <td>8.234098</td>\n",
              "      <td>1.681667</td>\n",
              "      <td>0.08</td>\n",
              "      <td>64</td>\n",
              "      <td>{'learning_rate': 0.08, 'min_data_in_leaf': 64}</td>\n",
              "      <td>-7.655887</td>\n",
              "      <td>-6.357202</td>\n",
              "      <td>-5.657410</td>\n",
              "      <td>-6.556833</td>\n",
              "      <td>0.827996</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.333362</td>\n",
              "      <td>-5.757166</td>\n",
              "      <td>-6.031544</td>\n",
              "      <td>-5.707357</td>\n",
              "      <td>0.287200</td>\n",
              "      <td>-0.849476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>195.732081</td>\n",
              "      <td>2.392888</td>\n",
              "      <td>7.542417</td>\n",
              "      <td>0.209229</td>\n",
              "      <td>0.01</td>\n",
              "      <td>58</td>\n",
              "      <td>{'learning_rate': 0.01, 'min_data_in_leaf': 58}</td>\n",
              "      <td>-8.498353</td>\n",
              "      <td>-7.615193</td>\n",
              "      <td>-6.611726</td>\n",
              "      <td>-7.575091</td>\n",
              "      <td>0.770734</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.860466</td>\n",
              "      <td>-7.419506</td>\n",
              "      <td>-7.804727</td>\n",
              "      <td>-7.361566</td>\n",
              "      <td>0.387664</td>\n",
              "      <td>-0.213525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203.481364</td>\n",
              "      <td>3.411693</td>\n",
              "      <td>7.841384</td>\n",
              "      <td>1.339718</td>\n",
              "      <td>0.062</td>\n",
              "      <td>85</td>\n",
              "      <td>{'learning_rate': 0.062, 'min_data_in_leaf': 85}</td>\n",
              "      <td>-7.625060</td>\n",
              "      <td>-6.370864</td>\n",
              "      <td>-5.687565</td>\n",
              "      <td>-6.561163</td>\n",
              "      <td>0.802343</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.412312</td>\n",
              "      <td>-5.855130</td>\n",
              "      <td>-6.141463</td>\n",
              "      <td>-5.802968</td>\n",
              "      <td>0.299951</td>\n",
              "      <td>-0.758194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201.468571</td>\n",
              "      <td>7.448985</td>\n",
              "      <td>8.829461</td>\n",
              "      <td>2.508677</td>\n",
              "      <td>0.076</td>\n",
              "      <td>45</td>\n",
              "      <td>{'learning_rate': 0.076, 'min_data_in_leaf': 45}</td>\n",
              "      <td>-7.616364</td>\n",
              "      <td>-6.363570</td>\n",
              "      <td>-5.670653</td>\n",
              "      <td>-6.550196</td>\n",
              "      <td>0.805220</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.345266</td>\n",
              "      <td>-5.768852</td>\n",
              "      <td>-6.052817</td>\n",
              "      <td>-5.722312</td>\n",
              "      <td>0.290725</td>\n",
              "      <td>-0.827884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206.265570</td>\n",
              "      <td>6.867411</td>\n",
              "      <td>8.409604</td>\n",
              "      <td>2.059425</td>\n",
              "      <td>0.085</td>\n",
              "      <td>84</td>\n",
              "      <td>{'learning_rate': 0.085, 'min_data_in_leaf': 84}</td>\n",
              "      <td>-7.613725</td>\n",
              "      <td>-6.354042</td>\n",
              "      <td>-5.639351</td>\n",
              "      <td>-6.535706</td>\n",
              "      <td>0.816207</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.325782</td>\n",
              "      <td>-5.740524</td>\n",
              "      <td>-6.003460</td>\n",
              "      <td>-5.689922</td>\n",
              "      <td>0.278965</td>\n",
              "      <td>-0.845784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200.146811</td>\n",
              "      <td>4.288425</td>\n",
              "      <td>8.262067</td>\n",
              "      <td>0.788359</td>\n",
              "      <td>0.041</td>\n",
              "      <td>43</td>\n",
              "      <td>{'learning_rate': 0.041, 'min_data_in_leaf': 43}</td>\n",
              "      <td>-7.667145</td>\n",
              "      <td>-6.418632</td>\n",
              "      <td>-5.650671</td>\n",
              "      <td>-6.578816</td>\n",
              "      <td>0.830978</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.519991</td>\n",
              "      <td>-6.027504</td>\n",
              "      <td>-6.313399</td>\n",
              "      <td>-5.953631</td>\n",
              "      <td>0.328092</td>\n",
              "      <td>-0.625185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>197.601803</td>\n",
              "      <td>2.459887</td>\n",
              "      <td>7.341037</td>\n",
              "      <td>0.643270</td>\n",
              "      <td>0.03</td>\n",
              "      <td>96</td>\n",
              "      <td>{'learning_rate': 0.03, 'min_data_in_leaf': 96}</td>\n",
              "      <td>-7.691362</td>\n",
              "      <td>-6.477534</td>\n",
              "      <td>-5.687901</td>\n",
              "      <td>-6.618932</td>\n",
              "      <td>0.823998</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.637971</td>\n",
              "      <td>-6.175413</td>\n",
              "      <td>-6.472258</td>\n",
              "      <td>-6.095214</td>\n",
              "      <td>0.345285</td>\n",
              "      <td>-0.523718</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_train_score      diff\n",
              "0     204.562277      4.050206  ...         0.287200 -0.849476\n",
              "0     195.732081      2.392888  ...         0.387664 -0.213525\n",
              "0     203.481364      3.411693  ...         0.299951 -0.758194\n",
              "0     201.468571      7.448985  ...         0.290725 -0.827884\n",
              "0     206.265570      6.867411  ...         0.278965 -0.845784\n",
              "0     200.146811      4.288425  ...         0.328092 -0.625185\n",
              "0     197.601803      2.459887  ...         0.345285 -0.523718\n",
              "\n",
              "[7 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xUTr636r9H_",
        "outputId": "6318f4a1-d2b1-4759-9cfb-c0f9e05d5674"
      },
      "source": [
        "model_4 = CatBoostRegressor(learning_rate =  0.01, min_data_in_leaf =  58, logging_level=\"Silent\", iterations=130)\r\n",
        "model_4.fit(k4_train, k4_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7fcfefea54a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMPjEuHLQTCM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeEL4z2Mbhp_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzKV5X6hvpvG"
      },
      "source": [
        "# **Base Model_5 LightGBM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv1RWqnfbiY8"
      },
      "source": [
        "a = pd.DataFrame()\r\n",
        "for i in range(7):    \r\n",
        "    params = {'learning_rate' : np.round(np.random.rand(1)/10,3).tolist(),\r\n",
        "              'min_data_in_leaf' : np.random.randint(30,113, size=1).tolist(),\r\n",
        "              'num_leaves' : np.random.randint(30,120, size=1).tolist()}\r\n",
        "\r\n",
        "    lgbm = LGBMRegressor()\r\n",
        "    clf = GridSearchCV(estimator=lgbm, param_grid=params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, return_train_score=True)\r\n",
        "    clf.fit(k5_train, k5_test)\r\n",
        "    b = pd.DataFrame(clf.cv_results_)\r\n",
        "    a = pd.concat([a,b])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "Re5Wf3XMbiY8",
        "outputId": "8ad952d3-eaff-4aa0-b66f-c920c0075c34"
      },
      "source": [
        "a['diff'] = a['mean_test_score'] - a['mean_train_score']\r\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_min_data_in_leaf</th>\n",
              "      <th>param_num_leaves</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146.360600</td>\n",
              "      <td>3.862081</td>\n",
              "      <td>19.917107</td>\n",
              "      <td>2.175597</td>\n",
              "      <td>0.089</td>\n",
              "      <td>92</td>\n",
              "      <td>79</td>\n",
              "      <td>{'learning_rate': 0.089, 'min_data_in_leaf': 9...</td>\n",
              "      <td>-7.434892</td>\n",
              "      <td>-6.621093</td>\n",
              "      <td>-6.229270</td>\n",
              "      <td>-6.761752</td>\n",
              "      <td>0.502142</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.892678</td>\n",
              "      <td>-5.186086</td>\n",
              "      <td>-5.336751</td>\n",
              "      <td>-5.138505</td>\n",
              "      <td>0.184388</td>\n",
              "      <td>-1.623247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125.157988</td>\n",
              "      <td>2.091329</td>\n",
              "      <td>15.555063</td>\n",
              "      <td>0.771899</td>\n",
              "      <td>0.074</td>\n",
              "      <td>77</td>\n",
              "      <td>49</td>\n",
              "      <td>{'learning_rate': 0.074, 'min_data_in_leaf': 7...</td>\n",
              "      <td>-7.436129</td>\n",
              "      <td>-6.556936</td>\n",
              "      <td>-6.082465</td>\n",
              "      <td>-6.691843</td>\n",
              "      <td>0.560804</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.127670</td>\n",
              "      <td>-5.454839</td>\n",
              "      <td>-5.604500</td>\n",
              "      <td>-5.395670</td>\n",
              "      <td>0.199110</td>\n",
              "      <td>-1.296173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>138.036163</td>\n",
              "      <td>2.092514</td>\n",
              "      <td>17.294474</td>\n",
              "      <td>1.237736</td>\n",
              "      <td>0.022</td>\n",
              "      <td>100</td>\n",
              "      <td>46</td>\n",
              "      <td>{'learning_rate': 0.022, 'min_data_in_leaf': 1...</td>\n",
              "      <td>-7.507970</td>\n",
              "      <td>-6.812343</td>\n",
              "      <td>-6.057160</td>\n",
              "      <td>-6.792491</td>\n",
              "      <td>0.592457</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.835271</td>\n",
              "      <td>-6.259846</td>\n",
              "      <td>-6.469700</td>\n",
              "      <td>-6.188272</td>\n",
              "      <td>0.263903</td>\n",
              "      <td>-0.604219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>152.460183</td>\n",
              "      <td>3.376623</td>\n",
              "      <td>18.949485</td>\n",
              "      <td>1.357921</td>\n",
              "      <td>0.034</td>\n",
              "      <td>100</td>\n",
              "      <td>78</td>\n",
              "      <td>{'learning_rate': 0.034, 'min_data_in_leaf': 1...</td>\n",
              "      <td>-7.405523</td>\n",
              "      <td>-6.560276</td>\n",
              "      <td>-6.034026</td>\n",
              "      <td>-6.666608</td>\n",
              "      <td>0.564937</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.389676</td>\n",
              "      <td>-5.774196</td>\n",
              "      <td>-5.955057</td>\n",
              "      <td>-5.706310</td>\n",
              "      <td>0.235754</td>\n",
              "      <td>-0.960298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143.962533</td>\n",
              "      <td>3.311683</td>\n",
              "      <td>16.168720</td>\n",
              "      <td>0.745065</td>\n",
              "      <td>0.005</td>\n",
              "      <td>80</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.005, 'min_data_in_leaf': 8...</td>\n",
              "      <td>-10.182938</td>\n",
              "      <td>-9.939481</td>\n",
              "      <td>-9.036646</td>\n",
              "      <td>-9.719688</td>\n",
              "      <td>0.493104</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.172816</td>\n",
              "      <td>-9.473449</td>\n",
              "      <td>-9.800658</td>\n",
              "      <td>-9.482308</td>\n",
              "      <td>0.256392</td>\n",
              "      <td>-0.237381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>163.437983</td>\n",
              "      <td>1.338426</td>\n",
              "      <td>19.422637</td>\n",
              "      <td>0.258524</td>\n",
              "      <td>0.013</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>{'learning_rate': 0.013, 'min_data_in_leaf': 6...</td>\n",
              "      <td>-7.962132</td>\n",
              "      <td>-7.481812</td>\n",
              "      <td>-6.635393</td>\n",
              "      <td>-7.359779</td>\n",
              "      <td>0.548470</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.471019</td>\n",
              "      <td>-6.851560</td>\n",
              "      <td>-7.081490</td>\n",
              "      <td>-6.801356</td>\n",
              "      <td>0.251739</td>\n",
              "      <td>-0.558422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>114.960509</td>\n",
              "      <td>2.287053</td>\n",
              "      <td>13.443021</td>\n",
              "      <td>1.001593</td>\n",
              "      <td>0.055</td>\n",
              "      <td>41</td>\n",
              "      <td>31</td>\n",
              "      <td>{'learning_rate': 0.055, 'min_data_in_leaf': 4...</td>\n",
              "      <td>-7.386535</td>\n",
              "      <td>-6.557217</td>\n",
              "      <td>-5.964029</td>\n",
              "      <td>-6.635927</td>\n",
              "      <td>0.583396</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.339150</td>\n",
              "      <td>-5.667614</td>\n",
              "      <td>-5.854938</td>\n",
              "      <td>-5.620567</td>\n",
              "      <td>0.213181</td>\n",
              "      <td>-1.015360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_train_score      diff\n",
              "0     146.360600      3.862081  ...         0.184388 -1.623247\n",
              "0     125.157988      2.091329  ...         0.199110 -1.296173\n",
              "0     138.036163      2.092514  ...         0.263903 -0.604219\n",
              "0     152.460183      3.376623  ...         0.235754 -0.960298\n",
              "0     143.962533      3.311683  ...         0.256392 -0.237381\n",
              "0     163.437983      1.338426  ...         0.251739 -0.558422\n",
              "0     114.960509      2.287053  ...         0.213181 -1.015360\n",
              "\n",
              "[7 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaO2fUeDbiY9",
        "outputId": "335d081f-8bdf-4a3f-b032-c5229605aaf2"
      },
      "source": [
        "model_5 = LGBMRegressor(learning_rate =  0.005, min_data_in_leaf =  80, num_leaves = 42)\r\n",
        "model_5.fit(k5_train, k5_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.005, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=80,\n",
              "              min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=42,\n",
              "              objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
              "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
              "              subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urhr9iDDvxzL"
      },
      "source": [
        "# **Saving the session to prevent from re-running.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvMNyw43QuiG"
      },
      "source": [
        "filename = 'copy_globalsave_1.pkl'\r\n",
        "dill.dump_session(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJrQeT1RFks"
      },
      "source": [
        "!cp copy_globalsave.pkl /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo4nsM4bRYQ2"
      },
      "source": [
        "dill.load_session('/content/drive/MyDrive/copy_globalsave.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymcrGo-5wNUO"
      },
      "source": [
        "# **Predicting the values on the 5 base models and creating a Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaevt58ObiY9"
      },
      "source": [
        "k1_pred = pd.Series(model_1.predict(X_train_D2))\r\n",
        "k2_pred = pd.Series(model_2.predict(X_train_D2))\r\n",
        "k3_pred = pd.Series(model_3.predict(X_train_D2))\r\n",
        "k4_pred = pd.Series(model_4.predict(X_train_D2))\r\n",
        "k5_pred = pd.Series(model_5.predict(X_train_D2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "If97SVSXplgO",
        "outputId": "cd865b42-1b5d-4bc3-8dc5-2c3315388005"
      },
      "source": [
        "X_train_D2_pred = pd.concat([pd.DataFrame(k1_pred, columns=['k1_pred']), pd.DataFrame(k2_pred,columns=['k2_pred']),\\\r\n",
        "           pd.DataFrame(k3_pred,columns=['k3_pred']),pd.DataFrame(k4_pred,columns=['k4_pred']),\\\r\n",
        "           pd.DataFrame(k5_pred,columns=['k5_pred'])],axis=1)\r\n",
        "\r\n",
        "X_train_D2_pred.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1_pred</th>\n",
              "      <th>k2_pred</th>\n",
              "      <th>k3_pred</th>\n",
              "      <th>k4_pred</th>\n",
              "      <th>k5_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.213988</td>\n",
              "      <td>1.212713</td>\n",
              "      <td>0.802246</td>\n",
              "      <td>0.677279</td>\n",
              "      <td>0.951471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.213584</td>\n",
              "      <td>1.212308</td>\n",
              "      <td>0.232422</td>\n",
              "      <td>0.662477</td>\n",
              "      <td>0.824897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    k1_pred   k2_pred   k3_pred   k4_pred   k5_pred\n",
              "0  1.213988  1.212713  0.802246  0.677279  0.951471\n",
              "1  1.213584  1.212308  0.232422  0.662477  0.824897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afB1vZLWiEmM"
      },
      "source": [
        "test_pred_1 = pd.Series(model_1.predict(X_test))\r\n",
        "test_pred_2 = pd.Series(model_2.predict(X_test))\r\n",
        "test_pred_3 = pd.Series(model_3.predict(X_test))\r\n",
        "test_pred_4 = pd.Series(model_4.predict(X_test))\r\n",
        "test_pred_5 = pd.Series(model_5.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4CpUT5oVidLR",
        "outputId": "e2d353f2-c0d7-48fc-e003-253700474b61"
      },
      "source": [
        "predictions = pd.concat([pd.DataFrame(test_pred_1, columns=['test_pred_1']), pd.DataFrame(test_pred_2,columns=['test_pred_2']),\\\r\n",
        "           pd.DataFrame(test_pred_3,columns=['test_pred_3']),pd.DataFrame(test_pred_4,columns=['test_pred_4']),\\\r\n",
        "           pd.DataFrame(test_pred_5,columns=['test_pred_5'])],axis=1)\r\n",
        "\r\n",
        "predictions.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_pred_1</th>\n",
              "      <th>test_pred_2</th>\n",
              "      <th>test_pred_3</th>\n",
              "      <th>test_pred_4</th>\n",
              "      <th>test_pred_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.213988</td>\n",
              "      <td>1.212713</td>\n",
              "      <td>0.613037</td>\n",
              "      <td>0.662477</td>\n",
              "      <td>0.884894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.213584</td>\n",
              "      <td>1.212308</td>\n",
              "      <td>1.284668</td>\n",
              "      <td>0.908849</td>\n",
              "      <td>1.077123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_pred_1  test_pred_2  test_pred_3  test_pred_4  test_pred_5\n",
              "0     1.213988     1.212713     0.613037     0.662477     0.884894\n",
              "1     1.213584     1.212308     1.284668     0.908849     1.077123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8UyZ75aw-iS"
      },
      "source": [
        "# **Creating a meta model using predcited values of X_train_D2 and it's true values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHLl62-ni7yG",
        "outputId": "3c20ed05-83f2-4247-e745-a80dcb26c515"
      },
      "source": [
        "for i in range(15):\r\n",
        "    \r\n",
        "    lr = np.round(np.random.rand()/10,3)\r\n",
        "    num_leaves = np.random.randint(30,150)\r\n",
        "    min_data_in_leaf = np.random.randint(50,150)\r\n",
        "    \r\n",
        "    lgb = LGBMRegressor(learning_rate=lr ,num_leaves=num_leaves ,min_data_in_leaf=min_data_in_leaf)\r\n",
        "    lgb.fit(X_train_D2_pred, y_train_D2)\r\n",
        "    \r\n",
        "    # Calculating the mse for train values to check if the model is overfitting or underfitting\r\n",
        "    train_pred = lgb.predict(X_train_D2_pred)\r\n",
        "\r\n",
        "    train_m_s_e = mse(y_train_D2,train_pred)\r\n",
        "    \r\n",
        "    # After training the model, we are trying to predict the model on X_val to check it's accuracy\r\n",
        "    y_pred = lgb.predict(predictions)\r\n",
        "    \r\n",
        "    # Now that it has predicted the values for X_val, we are calculating it's rmse\r\n",
        "    m_s_e = mse(y_test,y_pred)\r\n",
        "\r\n",
        "    print(f\"For learning rate {lr}, num_leaves {num_leaves} and min_data_in_leaf {min_data_in_leaf}, the train MSE is {train_m_s_e} and valid MSE is {m_s_e} diff is {m_s_e - train_m_s_e}\")\r\n",
        "    print('*'*80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For learning rate 0.099, num_leaves 100 and min_data_in_leaf 138, the train MSE is 5.901566823311719 and valid MSE is 6.314696340867779 diff is 0.41312951755605987\n",
            "********************************************************************************\n",
            "For learning rate 0.018, num_leaves 76 and min_data_in_leaf 75, the train MSE is 6.165910007452854 and valid MSE is 6.197485271639661 diff is 0.03157526418680767\n",
            "********************************************************************************\n",
            "For learning rate 0.071, num_leaves 135 and min_data_in_leaf 114, the train MSE is 5.900120806853764 and valid MSE is 6.313768139993319 diff is 0.41364733313955515\n",
            "********************************************************************************\n",
            "For learning rate 0.049, num_leaves 133 and min_data_in_leaf 101, the train MSE is 5.917993503037619 and valid MSE is 6.301181571326875 diff is 0.38318806828925656\n",
            "********************************************************************************\n",
            "For learning rate 0.054, num_leaves 53 and min_data_in_leaf 107, the train MSE is 5.947786808622934 and valid MSE is 6.301702254301726 diff is 0.3539154456787923\n",
            "********************************************************************************\n",
            "For learning rate 0.041, num_leaves 31 and min_data_in_leaf 108, the train MSE is 5.988083402160238 and valid MSE is 6.283198565546256 diff is 0.2951151633860176\n",
            "********************************************************************************\n",
            "For learning rate 0.017, num_leaves 137 and min_data_in_leaf 136, the train MSE is 6.190431311853975 and valid MSE is 6.205760298939965 diff is 0.015328987085990065\n",
            "********************************************************************************\n",
            "For learning rate 0.053, num_leaves 87 and min_data_in_leaf 58, the train MSE is 5.923998100345739 and valid MSE is 6.300138843664553 diff is 0.376140743318814\n",
            "********************************************************************************\n",
            "For learning rate 0.03, num_leaves 114 and min_data_in_leaf 55, the train MSE is 5.963503794685247 and valid MSE is 6.238923214884605 diff is 0.2754194201993583\n",
            "********************************************************************************\n",
            "For learning rate 0.078, num_leaves 72 and min_data_in_leaf 106, the train MSE is 5.917861458296095 and valid MSE is 6.308357179657265 diff is 0.3904957213611704\n",
            "********************************************************************************\n",
            "For learning rate 0.036, num_leaves 57 and min_data_in_leaf 110, the train MSE is 5.974325557094924 and valid MSE is 6.270076042962605 diff is 0.29575048586768027\n",
            "********************************************************************************\n",
            "For learning rate 0.007, num_leaves 101 and min_data_in_leaf 118, the train MSE is 7.598571916226548 and valid MSE is 7.045280208821461 diff is -0.5532917074050863\n",
            "********************************************************************************\n",
            "For learning rate 0.002, num_leaves 114 and min_data_in_leaf 59, the train MSE is 10.345361976385654 and valid MSE is 9.275870732063167 diff is -1.0694912443224869\n",
            "********************************************************************************\n",
            "For learning rate 0.008, num_leaves 139 and min_data_in_leaf 62, the train MSE is 7.296277384893396 and valid MSE is 6.832466054112743 diff is -0.4638113307806533\n",
            "********************************************************************************\n",
            "For learning rate 0.038, num_leaves 85 and min_data_in_leaf 126, the train MSE is 5.954755358005891 and valid MSE is 6.275622618302095 diff is 0.32086726029620394\n",
            "********************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDi1pfxNesbG",
        "outputId": "b14d1a26-15c6-4aea-8bec-b475d7bd66cc"
      },
      "source": [
        "meta_model = LGBMRegressor(learning_rate=0.007,num_leaves=101 ,min_data_in_leaf=118)\r\n",
        "meta_model.fit(X_train_D2_pred, y_train_D2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.007, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001,\n",
              "              min_data_in_leaf=118, min_split_gain=0.0, n_estimators=100,\n",
              "              n_jobs=-1, num_leaves=101, objective=None, random_state=None,\n",
              "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIKufAUJ0Pss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qusujMg40PpI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkYqoTiUpHXM"
      },
      "source": [
        "# Now splitting the values for the submission\r\n",
        "val = X_test[(X_test['day']>1913) & (X_test['day']<1942)]\r\n",
        "tst = X_test[X_test['day']>1941]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0weCx-A9qdwz"
      },
      "source": [
        "final_1_val = model_1.predict(val)\r\n",
        "final_1_tst = model_1.predict(tst)\r\n",
        "\r\n",
        "final_2_val = model_2.predict(val)\r\n",
        "final_2_tst = model_2.predict(tst)\r\n",
        "\r\n",
        "final_3_val = model_3.predict(val)\r\n",
        "final_3_tst = model_3.predict(tst)\r\n",
        "\r\n",
        "final_4_val = model_4.predict(val)\r\n",
        "final_4_tst = model_4.predict(tst)\r\n",
        "\r\n",
        "final_5_val = model_5.predict(val)\r\n",
        "final_5_tst = model_5.predict(tst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iOsQ5M0arBck",
        "outputId": "45efa9eb-9bb5-4f96-fe06-36e05c9e7a1d"
      },
      "source": [
        "final_val_preds = pd.concat([pd.DataFrame(final_1_val, columns=['final_1_val']), pd.DataFrame(final_2_val,columns=['final_2_val']),\\\r\n",
        "           pd.DataFrame(final_3_val,columns=['final_3_val']),pd.DataFrame(final_4_val,columns=['final_4_val']),\\\r\n",
        "           pd.DataFrame(final_5_val,columns=['final_5_val'])],axis=1)\r\n",
        "\r\n",
        "final_val_preds.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>final_1_val</th>\n",
              "      <th>final_2_val</th>\n",
              "      <th>final_3_val</th>\n",
              "      <th>final_4_val</th>\n",
              "      <th>final_5_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.213988</td>\n",
              "      <td>1.212713</td>\n",
              "      <td>0.887939</td>\n",
              "      <td>0.823942</td>\n",
              "      <td>1.056554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.213584</td>\n",
              "      <td>1.212308</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>0.667475</td>\n",
              "      <td>0.937174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   final_1_val  final_2_val  final_3_val  final_4_val  final_5_val\n",
              "0     1.213988     1.212713     0.887939     0.823942     1.056554\n",
              "1     1.213584     1.212308     0.649902     0.667475     0.937174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "519mH-awrWM2",
        "outputId": "fd324a7e-065b-4799-d2c3-32fd69468da7"
      },
      "source": [
        "final_tst_preds = pd.concat([pd.DataFrame(final_1_tst, columns=['final_1_tst']), pd.DataFrame(final_2_tst,columns=['final_2_tst']),\\\r\n",
        "           pd.DataFrame(final_3_tst,columns=['final_3_tst']),pd.DataFrame(final_4_tst,columns=['final_4_tst']),\\\r\n",
        "           pd.DataFrame(final_5_tst,columns=['final_5_tst'])],axis=1)\r\n",
        "\r\n",
        "final_tst_preds.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>final_1_tst</th>\n",
              "      <th>final_2_tst</th>\n",
              "      <th>final_3_tst</th>\n",
              "      <th>final_4_tst</th>\n",
              "      <th>final_5_tst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.213988</td>\n",
              "      <td>1.212713</td>\n",
              "      <td>0.595947</td>\n",
              "      <td>0.667475</td>\n",
              "      <td>0.914447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.213584</td>\n",
              "      <td>1.212308</td>\n",
              "      <td>0.357910</td>\n",
              "      <td>0.662477</td>\n",
              "      <td>0.824897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   final_1_tst  final_2_tst  final_3_tst  final_4_tst  final_5_tst\n",
              "0     1.213988     1.212713     0.595947     0.667475     0.914447\n",
              "1     1.213584     1.212308     0.357910     0.662477     0.824897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ale5BW_BrpE9"
      },
      "source": [
        "pred_val_array = meta_model.predict(final_val_preds)\r\n",
        "pred_test_array = meta_model.predict(final_tst_preds)\r\n",
        "\r\n",
        "pred_val_array = np.reshape(pred_val_array, (-1, 28),order = 'F')\r\n",
        "pred_test_array = np.reshape(pred_test_array, (-1, 28),order = 'F')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "B6FLQTRGsA1F",
        "outputId": "a6652c10-753d-44a3-84a7-1cf9ce77470f"
      },
      "source": [
        "sub = pd.read_csv(\"sample_submission.csv\")\r\n",
        "sub_1 = sub.iloc[:30490,:]\r\n",
        "sub_2 = sub.iloc[30490:,:]\r\n",
        "f_cols = sub.columns[1:]\r\n",
        "\r\n",
        "for i in range(len(f_cols)):\r\n",
        "    sub_1[f_cols[i]] = pred_val_array[:,i]\r\n",
        "    sub_2[f_cols[i]] = pred_test_array[:,i]\r\n",
        "\r\n",
        "sub = pd.concat([sub_1,sub_2])\r\n",
        "sub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>1.008821</td>\n",
              "      <td>0.969648</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.780210</td>\n",
              "      <td>1.058942</td>\n",
              "      <td>0.945947</td>\n",
              "      <td>1.071161</td>\n",
              "      <td>0.995634</td>\n",
              "      <td>1.330632</td>\n",
              "      <td>1.096884</td>\n",
              "      <td>1.349534</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>0.862546</td>\n",
              "      <td>1.251115</td>\n",
              "      <td>0.992293</td>\n",
              "      <td>1.096884</td>\n",
              "      <td>1.100746</td>\n",
              "      <td>1.193208</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.038512</td>\n",
              "      <td>1.058942</td>\n",
              "      <td>1.065147</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.038512</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.038512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.793189</td>\n",
              "      <td>0.753662</td>\n",
              "      <td>0.848594</td>\n",
              "      <td>0.742245</td>\n",
              "      <td>0.778792</td>\n",
              "      <td>0.808171</td>\n",
              "      <td>0.862546</td>\n",
              "      <td>0.756158</td>\n",
              "      <td>0.731740</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.769317</td>\n",
              "      <td>0.843288</td>\n",
              "      <td>0.779491</td>\n",
              "      <td>0.812034</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.751470</td>\n",
              "      <td>0.848594</td>\n",
              "      <td>0.756951</td>\n",
              "      <td>0.810674</td>\n",
              "      <td>0.832726</td>\n",
              "      <td>0.778792</td>\n",
              "      <td>0.716541</td>\n",
              "      <td>0.772309</td>\n",
              "      <td>0.760631</td>\n",
              "      <td>0.772309</td>\n",
              "      <td>0.773150</td>\n",
              "      <td>0.754468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>0.801090</td>\n",
              "      <td>0.791574</td>\n",
              "      <td>0.743095</td>\n",
              "      <td>0.710382</td>\n",
              "      <td>0.801090</td>\n",
              "      <td>1.038512</td>\n",
              "      <td>0.952546</td>\n",
              "      <td>0.773150</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.737798</td>\n",
              "      <td>0.817468</td>\n",
              "      <td>0.808171</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>0.880778</td>\n",
              "      <td>0.767155</td>\n",
              "      <td>0.772770</td>\n",
              "      <td>0.843288</td>\n",
              "      <td>0.982287</td>\n",
              "      <td>1.038512</td>\n",
              "      <td>1.297372</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>1.007070</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.915374</td>\n",
              "      <td>1.016001</td>\n",
              "      <td>0.969648</td>\n",
              "      <td>1.065147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>1.744673</td>\n",
              "      <td>1.174411</td>\n",
              "      <td>0.929735</td>\n",
              "      <td>1.289802</td>\n",
              "      <td>1.230354</td>\n",
              "      <td>1.497883</td>\n",
              "      <td>2.177328</td>\n",
              "      <td>1.415720</td>\n",
              "      <td>1.275015</td>\n",
              "      <td>1.096884</td>\n",
              "      <td>1.376129</td>\n",
              "      <td>1.434238</td>\n",
              "      <td>1.759173</td>\n",
              "      <td>2.204446</td>\n",
              "      <td>1.701488</td>\n",
              "      <td>1.216656</td>\n",
              "      <td>1.358930</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.415720</td>\n",
              "      <td>1.501199</td>\n",
              "      <td>2.177328</td>\n",
              "      <td>1.625229</td>\n",
              "      <td>1.297372</td>\n",
              "      <td>1.304719</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.349299</td>\n",
              "      <td>2.168582</td>\n",
              "      <td>1.981936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.127111</td>\n",
              "      <td>1.330632</td>\n",
              "      <td>1.157865</td>\n",
              "      <td>1.221156</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.368777</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.368777</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.054968</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.233586</td>\n",
              "      <td>1.329496</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.275015</td>\n",
              "      <td>1.060817</td>\n",
              "      <td>1.193208</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.329496</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.130954</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.272537</td>\n",
              "      <td>1.275015</td>\n",
              "      <td>1.563668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60975</th>\n",
              "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
              "      <td>0.817819</td>\n",
              "      <td>0.769317</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.961660</td>\n",
              "      <td>0.858096</td>\n",
              "      <td>0.902876</td>\n",
              "      <td>0.789243</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.758300</td>\n",
              "      <td>1.005922</td>\n",
              "      <td>1.058942</td>\n",
              "      <td>0.880778</td>\n",
              "      <td>0.992293</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.843288</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>0.858129</td>\n",
              "      <td>1.219005</td>\n",
              "      <td>0.812496</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>0.906384</td>\n",
              "      <td>0.915374</td>\n",
              "      <td>1.016001</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>1.071161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60976</th>\n",
              "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.859890</td>\n",
              "      <td>0.780210</td>\n",
              "      <td>0.859890</td>\n",
              "      <td>0.764844</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.781909</td>\n",
              "      <td>0.813411</td>\n",
              "      <td>0.902876</td>\n",
              "      <td>0.816276</td>\n",
              "      <td>1.016001</td>\n",
              "      <td>0.758300</td>\n",
              "      <td>1.016001</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.902876</td>\n",
              "      <td>0.880778</td>\n",
              "      <td>0.779491</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.737798</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.880778</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>0.775667</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.726745</td>\n",
              "      <td>1.003606</td>\n",
              "      <td>0.757754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60977</th>\n",
              "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
              "      <td>1.257981</td>\n",
              "      <td>0.895495</td>\n",
              "      <td>1.060817</td>\n",
              "      <td>0.816276</td>\n",
              "      <td>0.982287</td>\n",
              "      <td>1.193208</td>\n",
              "      <td>0.969648</td>\n",
              "      <td>1.349299</td>\n",
              "      <td>0.780210</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>0.877577</td>\n",
              "      <td>0.929068</td>\n",
              "      <td>1.147010</td>\n",
              "      <td>1.142785</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.071161</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>0.994609</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.096884</td>\n",
              "      <td>1.275015</td>\n",
              "      <td>1.016621</td>\n",
              "      <td>1.388151</td>\n",
              "      <td>0.858800</td>\n",
              "      <td>0.927419</td>\n",
              "      <td>0.993318</td>\n",
              "      <td>1.184010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60978</th>\n",
              "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>1.434238</td>\n",
              "      <td>1.003606</td>\n",
              "      <td>1.233586</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.119456</td>\n",
              "      <td>1.368777</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.297372</td>\n",
              "      <td>1.358930</td>\n",
              "      <td>1.329496</td>\n",
              "      <td>1.096884</td>\n",
              "      <td>1.130954</td>\n",
              "      <td>1.193208</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.275015</td>\n",
              "      <td>1.415720</td>\n",
              "      <td>1.668891</td>\n",
              "      <td>1.257981</td>\n",
              "      <td>1.518178</td>\n",
              "      <td>1.130954</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.147010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60979</th>\n",
              "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
              "      <td>1.267523</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.127111</td>\n",
              "      <td>0.920528</td>\n",
              "      <td>1.060817</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.272537</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.184010</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.241572</td>\n",
              "      <td>1.233586</td>\n",
              "      <td>1.388151</td>\n",
              "      <td>1.434238</td>\n",
              "      <td>1.127111</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>1.008821</td>\n",
              "      <td>1.120969</td>\n",
              "      <td>1.297372</td>\n",
              "      <td>1.007070</td>\n",
              "      <td>1.537916</td>\n",
              "      <td>1.349299</td>\n",
              "      <td>1.156122</td>\n",
              "      <td>1.215566</td>\n",
              "      <td>1.100746</td>\n",
              "      <td>1.612157</td>\n",
              "      <td>1.016621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60980 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id        F1  ...       F27       F28\n",
              "0      HOBBIES_1_001_CA_1_validation  1.008821  ...  1.241572  1.038512\n",
              "1      HOBBIES_1_002_CA_1_validation  0.895495  ...  0.773150  0.754468\n",
              "2      HOBBIES_1_003_CA_1_validation  0.801090  ...  0.969648  1.065147\n",
              "3      HOBBIES_1_004_CA_1_validation  1.744673  ...  2.168582  1.981936\n",
              "4      HOBBIES_1_005_CA_1_validation  1.203920  ...  1.275015  1.563668\n",
              "...                              ...       ...  ...       ...       ...\n",
              "60975    FOODS_3_823_WI_3_evaluation  0.817819  ...  0.895495  1.071161\n",
              "60976    FOODS_3_824_WI_3_evaluation  0.918212  ...  1.003606  0.757754\n",
              "60977    FOODS_3_825_WI_3_evaluation  1.257981  ...  0.993318  1.184010\n",
              "60978    FOODS_3_826_WI_3_evaluation  1.119456  ...  1.184010  1.147010\n",
              "60979    FOODS_3_827_WI_3_evaluation  1.267523  ...  1.612157  1.016621\n",
              "\n",
              "[60980 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA0ZCInZsJsu"
      },
      "source": [
        "sub.to_csv(\"stack_model_8.csv\",index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntd5-OTWsOyi",
        "outputId": "e0987e23-db3b-4654-a1f8-6f3cb7bad9bb"
      },
      "source": [
        "!kaggle competitions submit -c m5-forecasting-accuracy -f stack_model_8.csv -m \"Eigth stacked model\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 32.4M/32.4M [00:00<00:00, 60.0MB/s]\n",
            "Successfully submitted to M5 Forecasting - Accuracy"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lOsiwNk34VW"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    }
  ]
}