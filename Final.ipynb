{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vence-andersen/M5-Forecasting-Accuracy/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4OhKFN3OV4V"
      },
      "source": [
        "# **Removables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb9mP9vR0xs2"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKLYZAxA0xpl"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eumyA-8W0xmc"
      },
      "source": [
        "! kaggle competitions download -c m5-forecasting-accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN5KvqzP0xgu"
      },
      "source": [
        "!unzip sales_train_evaluation.csv.zip\r\n",
        "!unzip sales_train_validation.csv.zip\r\n",
        "!unzip sample_submission.csv.zip\r\n",
        "!unzip sell_prices.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6UhZ29OZFh"
      },
      "source": [
        "# **Importing modules required and reading the CSV files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbabL4M2yVWn"
      },
      "source": [
        "! pip install -q downcast\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "from lightgbm import LGBMRegressor\r\n",
        "from sklearn.metrics import mean_squared_error as mse\r\n",
        "from downcast import reduce\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZZ7gmWz0swc"
      },
      "source": [
        "sales = pd.read_csv(\"sales_train_evaluation.csv\")\r\n",
        "sell_price = pd.read_csv(\"sell_prices.csv\")\r\n",
        "cal = pd.read_csv(\"calendar.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmIHXanCOmsk"
      },
      "source": [
        "# **Function_1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "FgjtQvl81IbR",
        "outputId": "a359f282-11fc-42ac-f1ec-4c68e0221a49"
      },
      "source": [
        "# Picking a value in random to check it's accuracy\r\n",
        "test = sales.sample(random_state=13).reset_index(drop=True)\r\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_139_WI_1_evaluation</td>\n",
              "      <td>HOBBIES_1_139</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>WI_1</td>\n",
              "      <td>WI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 1947 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id        item_id  ... d_1940 d_1941\n",
              "0  HOBBIES_1_139_WI_1_evaluation  HOBBIES_1_139  ...      0      0\n",
              "\n",
              "[1 rows x 1947 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi7unQM6xDLh"
      },
      "source": [
        "def final_1(test):\r\n",
        "    \"\"\"This function predicts the demand of the product for the next 28 days\"\"\"\r\n",
        "\r\n",
        "    # We are creating new features required for the prediction for days from 1942 till 1969\r\n",
        "    for day in range(1942,1942+28):\r\n",
        "        test['d_' + str(day)] = np.int32(0)\r\n",
        "\r\n",
        "    test = reduce(test)\r\n",
        "    \r\n",
        "    # We are transforming our Time Series problem to Supervised Machine Learning Problem\r\n",
        "    data = pd.melt(test, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\r\n",
        "            var_name='day', value_name='demand')\r\n",
        "\r\n",
        "    # We are then merging the all the csv files together\r\n",
        "    data = data.merge(cal, left_on='day', right_on='d')\r\n",
        "    data = data.merge(sell_price,on=['store_id','item_id', 'wm_yr_wk'], how='left')\r\n",
        "\r\n",
        "    # We are then filling the missing places with the products avg sell_price\r\n",
        "    data['sell_price'].fillna(data.groupby('id')['sell_price'].transform('mean'), inplace=True)\r\n",
        "\r\n",
        "    # we are stripping the 'd_' from day column to make it an integer feature\r\n",
        "    data['day'] = data['day'].apply(lambda x: x.split('_')[1]).astype(np.int16)\r\n",
        "\r\n",
        "    #since weekday's are represented as wday with numbers and d is a duplicate column.\r\n",
        "    data.drop(['d','weekday','date'], axis=1, inplace=True) \r\n",
        "\r\n",
        "    # As we did a custom categorical encoding during the trainig of the best model, we need to to use the same categorical labels that we were created \r\n",
        "    # for every category, hence I created a dictonary for every category as a key and it's label as value and transported it here.\r\n",
        "\r\n",
        "    all_dicts = pickle.load(open('/content/drive/MyDrive/all_dict', 'rb'))\r\n",
        "\r\n",
        "    # all_dicts is a list which has multiple dictonaries in it.\r\n",
        "\r\n",
        "    IDs = all_dicts[0]; ITEM_ids = all_dicts[1]; DEPT_ids = all_dicts[2]; CAT_ids = all_dicts[3]; STORE_ids = all_dicts[4]\r\n",
        "    STATE_ids = all_dicts[5]; EVNT_nm_1 = all_dicts[6]; EVNT_nm_2 = all_dicts[7]; EVNT_typ_1 = all_dicts[8]; EVNT_typ_2 = all_dicts[9]\r\n",
        "\r\n",
        "    # we are applying the label value for our test data\r\n",
        "\r\n",
        "    data['id'] = data['id'].apply(lambda x:IDs.get(x)); data['item_id'] = data['item_id'].apply(lambda x:ITEM_ids.get(x));  \r\n",
        "    data['cat_id'] = data['cat_id'].apply(lambda x:CAT_ids.get(x)); data['store_id'] = data['store_id'].apply(lambda x:STORE_ids.get(x)); \r\n",
        "    data['state_id'] = data['state_id'].apply(lambda x:STATE_ids.get(x)); data['dept_id'] = data['dept_id'].apply(lambda x:DEPT_ids.get(x));\r\n",
        "    data['event_name_1'] = data['event_name_1'].apply(lambda x:EVNT_nm_1.get(x)); data['event_name_2'] = data['event_name_2'].apply(lambda x:EVNT_nm_2.get(x)); \r\n",
        "    data['event_type_1'] = data['event_type_1'].apply(lambda x:EVNT_typ_1.get(x)); data['event_type_2'] = data['event_type_2'].apply(lambda x:EVNT_typ_2.get(x)); \r\n",
        "\r\n",
        "    # we are filling the nan values with -1, as that was the label replacement during training of the best model\r\n",
        "    data['event_name_1'].fillna(-1, inplace=True); data['event_name_2'].fillna(-1, inplace=True);\r\n",
        "    data['event_type_1'].fillna(-1, inplace=True); data['event_type_2'].fillna(-1, inplace=True);\r\n",
        "\r\n",
        "    # We are then conberting the data type of the categorical features\r\n",
        "    data['event_name_1'] = data['event_name_1'].astype('int8'); data['event_name_2'] = data['event_name_2'].astype('int8')\r\n",
        "    data['event_type_1'] = data['event_type_1'].astype('int8'); data['event_type_2'] = data['event_type_2'].astype('int8')\r\n",
        "    data['id'] = data['id'].astype('int8'); data['dept_id'] = data['dept_id'].astype('int8'); data['cat_id'] = data['cat_id'].astype('int8');\r\n",
        "    data['state_id'] = data['state_id'].astype('int8')\r\n",
        "\r\n",
        "    # Adding lag shift features as those are good time series feature engineering steps.\r\n",
        "    lags = [28,30,35,42,49,56,63,70]\r\n",
        "    for lag in lags:\r\n",
        "        data[\"lag_\" + str(lag)] = data.groupby(\"id\")[\"demand\"].shift(lag).astype(np.float16)\r\n",
        "\r\n",
        "    # We are picking the data after 1000 days because from EDA we found out that there were no proper seasonal follows before that.\r\n",
        "    data = data[data['day']>1000]\r\n",
        "    data.reset_index(drop=True, inplace=True)\r\n",
        "\r\n",
        "    # we are then reading the best model we got while training\r\n",
        "    best = open('/content/drive/MyDrive/best_model','rb')\r\n",
        "    lgb = pickle.load(best)\r\n",
        "\r\n",
        "    # We are dropping demand as it's the target value\r\n",
        "    data.drop('demand', axis=1, inplace=True)\r\n",
        "\r\n",
        "    # We are splitting the data for validation and test and then predicting it's value\r\n",
        "    X_val = data[(data['day']>1913) & (data['day']<1942)]\r\n",
        "    pred_val_array = lgb.predict(X_val)\r\n",
        "\r\n",
        "    X_test = data[data['day']>1941]\r\n",
        "    pred_test_array = lgb.predict(X_test)\r\n",
        "\r\n",
        "    # We are then reshaping the predicted value\r\n",
        "    pred_val_array = np.reshape(pred_val_array, (-1, 28),order = 'F')\r\n",
        "    pred_test_array = np.reshape(pred_test_array, (-1, 28),order = 'F')\r\n",
        "\r\n",
        "    cols = ['F'+str(i) for i in range(1,29)]\r\n",
        "\r\n",
        "    vals = pd.concat([pd.DataFrame([test['id']], index=[0]),pd.DataFrame(pred_val_array, columns=cols)],axis=1).rename(columns={0:'ID'})\r\n",
        "    vals['ID'] = vals['ID'].apply(lambda x: x.replace('evaluation','validation'))\r\n",
        "    tst = pd.concat([pd.DataFrame([test['id']], index=[0]),pd.DataFrame(pred_test_array, columns=cols)],axis=1).rename(columns={0:'ID'})\r\n",
        "\r\n",
        "    return vals, tst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "K0g8HdFyEW7s",
        "outputId": "a621b598-3c31-44df-b30c-ca6e0d4f1f1f"
      },
      "source": [
        "vals, tst = final_1(test)\r\n",
        "print('Forecast sales from days 1914 till 1941 is:')\r\n",
        "display(vals)\r\n",
        "print('\\nForecast sales from days 1942 till 1969 is:')\r\n",
        "display(tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forecast sales from days 1914 till 1941 is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_139_WI_1_validation</td>\n",
              "      <td>0.427085</td>\n",
              "      <td>0.71657</td>\n",
              "      <td>0.343393</td>\n",
              "      <td>0.568409</td>\n",
              "      <td>0.330454</td>\n",
              "      <td>0.794805</td>\n",
              "      <td>0.489243</td>\n",
              "      <td>0.459894</td>\n",
              "      <td>0.750902</td>\n",
              "      <td>0.420226</td>\n",
              "      <td>0.525707</td>\n",
              "      <td>0.425969</td>\n",
              "      <td>0.607013</td>\n",
              "      <td>0.455384</td>\n",
              "      <td>0.291552</td>\n",
              "      <td>0.531099</td>\n",
              "      <td>0.458824</td>\n",
              "      <td>0.51533</td>\n",
              "      <td>0.363455</td>\n",
              "      <td>0.476559</td>\n",
              "      <td>0.402097</td>\n",
              "      <td>0.343486</td>\n",
              "      <td>0.520414</td>\n",
              "      <td>0.489011</td>\n",
              "      <td>0.513274</td>\n",
              "      <td>0.542959</td>\n",
              "      <td>0.416199</td>\n",
              "      <td>0.636495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              ID        F1  ...       F27       F28\n",
              "0  HOBBIES_1_139_WI_1_validation  0.427085  ...  0.416199  0.636495\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Forecast sales from days 1942 till 1969 is:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_139_WI_1_evaluation</td>\n",
              "      <td>0.313194</td>\n",
              "      <td>0.474262</td>\n",
              "      <td>0.416199</td>\n",
              "      <td>0.388617</td>\n",
              "      <td>0.564641</td>\n",
              "      <td>0.280988</td>\n",
              "      <td>0.33888</td>\n",
              "      <td>0.285426</td>\n",
              "      <td>0.546403</td>\n",
              "      <td>0.404203</td>\n",
              "      <td>0.669596</td>\n",
              "      <td>0.444401</td>\n",
              "      <td>0.554913</td>\n",
              "      <td>0.34684</td>\n",
              "      <td>0.267322</td>\n",
              "      <td>0.473971</td>\n",
              "      <td>0.461642</td>\n",
              "      <td>0.651972</td>\n",
              "      <td>0.469221</td>\n",
              "      <td>0.401177</td>\n",
              "      <td>0.291985</td>\n",
              "      <td>0.335359</td>\n",
              "      <td>0.410047</td>\n",
              "      <td>0.435015</td>\n",
              "      <td>0.487305</td>\n",
              "      <td>0.343876</td>\n",
              "      <td>0.350149</td>\n",
              "      <td>0.238236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              ID        F1  ...       F27       F28\n",
              "0  HOBBIES_1_139_WI_1_evaluation  0.313194  ...  0.350149  0.238236\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTFl-mslPza7"
      },
      "source": [
        "# **Function_2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "nJUtF96bIQfJ",
        "outputId": "28b5b0ad-b38c-4cc9-9c28-21bcf8eae672"
      },
      "source": [
        "test = sales.sample(random_state=33).reset_index(drop=True)\r\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOUSEHOLD_2_484_CA_2_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_484</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>CA_2</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 1947 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                id          item_id  ... d_1940 d_1941\n",
              "0  HOUSEHOLD_2_484_CA_2_evaluation  HOUSEHOLD_2_484  ...      1      0\n",
              "\n",
              "[1 rows x 1947 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saUk0lZMGvZH"
      },
      "source": [
        "def final_2(test,y_true):\r\n",
        "    \"\"\"This function predicts the demand of the product for the next 28 days\"\"\"\r\n",
        "\r\n",
        "    # We are creating new features required for the prediction for days from 1942 till 1969\r\n",
        "    for day in range(1942,1942+28):\r\n",
        "        test['d_' + str(day)] = np.int32(0)\r\n",
        "\r\n",
        "    test = reduce(test)\r\n",
        "    \r\n",
        "    # We are transforming our Time Series problem to Supervised Machine Learning Problem\r\n",
        "    data = pd.melt(test, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\r\n",
        "            var_name='day', value_name='demand')\r\n",
        "\r\n",
        "    # We are then merging the all the csv files together\r\n",
        "    data = data.merge(cal, left_on='day', right_on='d')\r\n",
        "    data = data.merge(sell_price,on=['store_id','item_id', 'wm_yr_wk'], how='left')\r\n",
        "\r\n",
        "    # We are then filling the missing places with the products avg sell_price\r\n",
        "    data['sell_price'].fillna(data.groupby('id')['sell_price'].transform('mean'), inplace=True)\r\n",
        "\r\n",
        "    # we are stripping the 'd_' from day column to make it an integer feature\r\n",
        "    data['day'] = data['day'].apply(lambda x: x.split('_')[1]).astype(np.int16)\r\n",
        "\r\n",
        "    #since weekday's are represented as wday with numbers and d is a duplicate column.\r\n",
        "    data.drop(['d','weekday','date'], axis=1, inplace=True) \r\n",
        "\r\n",
        "    # As we did a custom categorical encoding during the trainig of the best model, we need to to use the same categorical labels that we were created \r\n",
        "    # for every category, hence I created a dictonary for every category as a key and it's label as value and transported it here.\r\n",
        "\r\n",
        "    all_dicts = pickle.load(open('/content/drive/MyDrive/all_dict', 'rb'))\r\n",
        "\r\n",
        "    # all_dicts is a list which has multiple dictonaries in it.\r\n",
        "\r\n",
        "    IDs = all_dicts[0]; ITEM_ids = all_dicts[1]; DEPT_ids = all_dicts[2]; CAT_ids = all_dicts[3]; STORE_ids = all_dicts[4]\r\n",
        "    STATE_ids = all_dicts[5]; EVNT_nm_1 = all_dicts[6]; EVNT_nm_2 = all_dicts[7]; EVNT_typ_1 = all_dicts[8]; EVNT_typ_2 = all_dicts[9]\r\n",
        "\r\n",
        "    # we are applying the label value for our test data\r\n",
        "\r\n",
        "    data['id'] = data['id'].apply(lambda x:IDs.get(x)); data['item_id'] = data['item_id'].apply(lambda x:ITEM_ids.get(x));  \r\n",
        "    data['cat_id'] = data['cat_id'].apply(lambda x:CAT_ids.get(x)); data['store_id'] = data['store_id'].apply(lambda x:STORE_ids.get(x)); \r\n",
        "    data['state_id'] = data['state_id'].apply(lambda x:STATE_ids.get(x)); data['dept_id'] = data['dept_id'].apply(lambda x:DEPT_ids.get(x));\r\n",
        "    data['event_name_1'] = data['event_name_1'].apply(lambda x:EVNT_nm_1.get(x)); data['event_name_2'] = data['event_name_2'].apply(lambda x:EVNT_nm_2.get(x)); \r\n",
        "    data['event_type_1'] = data['event_type_1'].apply(lambda x:EVNT_typ_1.get(x)); data['event_type_2'] = data['event_type_2'].apply(lambda x:EVNT_typ_2.get(x)); \r\n",
        "\r\n",
        "    # we are filling the nan values with -1, as that was the label replacement during training of the best model\r\n",
        "    data['event_name_1'].fillna(-1, inplace=True); data['event_name_2'].fillna(-1, inplace=True);\r\n",
        "    data['event_type_1'].fillna(-1, inplace=True); data['event_type_2'].fillna(-1, inplace=True);\r\n",
        "\r\n",
        "    # We are then conberting the data type of the categorical features\r\n",
        "    data['event_name_1'] = data['event_name_1'].astype('int8'); data['event_name_2'] = data['event_name_2'].astype('int8')\r\n",
        "    data['event_type_1'] = data['event_type_1'].astype('int8'); data['event_type_2'] = data['event_type_2'].astype('int8')\r\n",
        "    data['id'] = data['id'].astype('int8'); data['dept_id'] = data['dept_id'].astype('int8'); data['cat_id'] = data['cat_id'].astype('int8');\r\n",
        "    data['state_id'] = data['state_id'].astype('int8')\r\n",
        "\r\n",
        "    # Adding lag shift features as those are good time series feature engineering steps.\r\n",
        "    lags = [28,30,35,42,49,56,63,70]\r\n",
        "    for lag in lags:\r\n",
        "        data[\"lag_\" + str(lag)] = data.groupby(\"id\")[\"demand\"].shift(lag).astype(np.float16)\r\n",
        "\r\n",
        "    # We are picking the data after 1000 days because from EDA we found out that there were no proper seasonal follows before that.\r\n",
        "    data = data[data['day']>1000]\r\n",
        "    data.reset_index(drop=True, inplace=True)\r\n",
        "\r\n",
        "    # we are then reading the best model we got while training\r\n",
        "    best = open('/content/drive/MyDrive/best_model','rb')\r\n",
        "    lgb = pickle.load(best)\r\n",
        "\r\n",
        "    # We are dropping demand as it's the target value\r\n",
        "    data.drop('demand', axis=1, inplace=True)\r\n",
        "\r\n",
        "    # We are then spliting the data for prediction and predicting the values\r\n",
        "    X_val = data[data['day']>1913]\r\n",
        "    y_pred = lgb.predict(X_val)\r\n",
        "\r\n",
        "    # We are then reshaping for calculating the rmse value\r\n",
        "    y_pred = np.reshape(y_pred, (-1, 28),order = 'F')\r\n",
        "\r\n",
        "    # We are calculating the rmse value\r\n",
        "    r_m_s_e = mse(y_true=y_true, y_pred=y_pred, squared=False)\r\n",
        "\r\n",
        "    return r_m_s_e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toskHHNoIRph",
        "outputId": "a065849e-7e27-4ff7-f46b-2954bcadaff0"
      },
      "source": [
        "r_m_s_e = final_2(test.iloc[:,:-28],test.iloc[:,-28:])\r\n",
        "print(f\"The RMSE score is {r_m_s_e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE score is 0.6650955041390069\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}